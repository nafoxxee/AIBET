#!/usr/bin/env python3
"""
AIBET Analytics Platform - KHL Parser
–ñ–∏–≤–æ–π –ø–∞—Ä—Å–∏–Ω–≥ –º–∞—Ç—á–µ–π –ö–•–õ —Å –ø—É–±–ª–∏—á–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
"""

import asyncio
import aiohttp
import asyncio
from bs4 import BeautifulSoup
from datetime import datetime, timedelta
from typing import List, Dict, Optional, Any
import logging
import re
import json

from database import Match, db_manager

logger = logging.getLogger(__name__)

class KHLParser:
    def __init__(self):
        self.base_url = "https://khl.ru"
        self.calendar_url = "https://khl.ru/calendar/"
        self.results_url = "https://khl.ru/games/"
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
    
    async def fetch_page(self, session: aiohttp.ClientSession, url: str) -> Optional[str]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
        try:
            async with session.get(url, headers=self.headers, timeout=aiohttp.ClientTimeout(total=10)) as response:
                if response.status == 200:
                    return await response.text()
                else:
                    logger.warning(f"HTTP {response.status} for {url}")
                    return None
        except Exception as e:
            logger.error(f"Error fetching {url}: {e}")
            return None
    
    def parse_match_time(self, time_str: str, date_str: str = None) -> Optional[datetime]:
        """–ü–∞—Ä—Å–∏–Ω–≥ –≤—Ä–µ–º–µ–Ω–∏ –º–∞—Ç—á–∞"""
        try:
            # KHL –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ñ–æ—Ä–º–∞—Ç "HH:MM" –∏ –¥–∞—Ç—É
            if time_str:
                time_parts = time_str.split(":")
                if len(time_parts) == 2:
                    hour, minute = int(time_parts[0]), int(time_parts[1])
                    
                    if date_str:
                        # –ü–∞—Ä—Å–∏–º –¥–∞—Ç—É –µ—Å–ª–∏ –µ—Å—Ç—å
                        date_obj = datetime.strptime(date_str, "%d.%m.%Y")
                        return date_obj.replace(hour=hour, minute=minute)
                    else:
                        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–µ–≥–æ–¥–Ω—è—à–Ω—é—é –¥–∞—Ç—É
                        today = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)
                        return today.replace(hour=hour, minute=minute)
            
            return datetime.now() + timedelta(hours=3)
        except Exception as e:
            logger.error(f"Error parsing time '{time_str}': {e}")
            return datetime.now() + timedelta(hours=3)
    
    def extract_score(self, match_element) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—á–µ—Ç–∞ –º–∞—Ç—á–∞"""
        try:
            # –ò—â–µ–º —Å—á–µ—Ç –≤ —Ä–∞–∑–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö
            score_elem = match_element.find("div", class_="score")
            if score_elem:
                score_text = score_elem.get_text(strip=True)
                # –§–æ—Ä–º–∞—Ç "3:2" –∏–ª–∏ "3:2 OT"
                score_match = re.search(r"(\d+:\d+)", score_text)
                if score_match:
                    return score_match.group(1)
            
            # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫
            score_elem = match_element.find("span", class_="score")
            if score_elem:
                return score_elem.get_text(strip=True)
            
            return ""
        except:
            return ""
    
    def extract_period(self, match_element) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–µ—Ä–∏–æ–¥–∞ –º–∞—Ç—á–∞"""
        try:
            # –ò—â–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–µ—Ä–∏–æ–¥–µ
            period_elem = match_element.find("div", class_="period")
            if period_elem:
                period_text = period_elem.get_text(strip=True).upper()
                if "OT" in period_text:
                    return "OT"
                elif "SO" in period_text:
                    return "SO"
                elif "3RD" in period_text or "3–ü" in period_text:
                    return "3rd"
            
            return "Regular"
        except:
            return "Regular"
    
    async def parse_calendar_page(self, html: str) -> List[Match]:
        """–ü–∞—Ä—Å–∏–Ω–≥ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∫–∞–ª–µ–Ω–¥–∞—Ä—è"""
        matches = []
        soup = BeautifulSoup(html, 'html.parser')
        
        # –ò—â–µ–º —Ç–∞–±–ª–∏—Ü—É —Å –º–∞—Ç—á–∞–º–∏
        match_table = soup.find("table", class_="calendar")
        if not match_table:
            # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫
            match_table = soup.find("div", class_="matches")
        
        if match_table:
            # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ —Å—Ç—Ä–æ–∫–∏ —Å –º–∞—Ç—á–∞–º–∏
            match_rows = match_table.find_all("tr")
            
            for row in match_rows:
                try:
                    # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
                    if row.find("th"):
                        continue
                    
                    cells = row.find_all("td")
                    if len(cells) < 4:
                        continue
                    
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ —è—á–µ–µ–∫
                    date_cell = cells[0] if len(cells) > 0 else None
                    time_cell = cells[1] if len(cells) > 1 else None
                    team1_cell = cells[2] if len(cells) > 2 else None
                    team2_cell = cells[3] if len(cells) > 3 else None
                    score_cell = cells[4] if len(cells) > 4 else None
                    
                    # –ö–æ–º–∞–Ω–¥—ã
                    team1 = team1_cell.get_text(strip=True) if team1_cell else ""
                    team2 = team2_cell.get_text(strip=True) if team2_cell else ""
                    
                    if not team1 or not team2:
                        continue
                    
                    # –í—Ä–µ–º—è –∏ –¥–∞—Ç–∞
                    time_text = time_cell.get_text(strip=True) if time_cell else ""
                    date_text = date_cell.get_text(strip=True) if date_cell else ""
                    
                    start_time = self.parse_match_time(time_text, date_text)
                    
                    # –°—á–µ—Ç
                    score = score_cell.get_text(strip=True) if score_cell else ""
                    
                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç–∞—Ç—É—Å
                    if score and ":" in score:
                        status = "finished"
                    else:
                        status = "upcoming"
                    
                    # –¢—É—Ä–Ω–∏—Ä (–æ–±—ã—á–Ω–æ —Ä–µ–≥—É–ª—è—Ä–Ω—ã–π —á–µ–º–ø–∏–æ–Ω–∞—Ç)
                    tournament = "KHL Regular Season"
                    
                    # –§–∏—á–∏ –¥–ª—è ML
                    features = {
                        "tournament": tournament,
                        "period": self.extract_period(row),
                        "format": "Regular",
                        "stage": "Regular Season",
                        "home_advantage": True  # –í –ö–•–õ –µ—Å—Ç—å –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–æ –¥–æ–º–∞—à–Ω–µ–π –ø–ª–æ—â–∞–¥–∫–∏
                    }
                    
                    match = Match(
                        sport="khl",
                        team1=team1,
                        team2=team2,
                        score=score,
                        status=status,
                        start_time=start_time,
                        features=features
                    )
                    
                    matches.append(match)
                    
                except Exception as e:
                    logger.error(f"Error parsing calendar row: {e}")
                    continue
        
        return matches
    
    async def parse_results_page(self, html: str) -> List[Match]:
        """–ü–∞—Ä—Å–∏–Ω–≥ —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏"""
        matches = []
        soup = BeautifulSoup(html, 'html.parser')
        
        # –ò—â–µ–º –∫–∞—Ä—Ç–æ—á–∫–∏ –º–∞—Ç—á–µ–π
        match_elements = soup.find_all("div", class_="game")
        
        for match_elem in match_elements:
            try:
                # –ö–æ–º–∞–Ω–¥—ã
                team1_elem = match_elem.find("div", class_="team1")
                team2_elem = match_elem.find("div", class_="team2")
                
                team1 = team1_elem.get_text(strip=True) if team1_elem else ""
                team2 = team2_elem.get_text(strip=True) if team2_elem else ""
                
                if not team1 or not team2:
                    continue
                
                # –°—á–µ—Ç
                score = self.extract_score(match_elem)
                
                # –°—Ç–∞—Ç—É—Å
                status = "finished" if score else "upcoming"
                
                # –í—Ä–µ–º—è
                time_elem = match_elem.find("div", class_="time")
                time_text = time_elem.get_text(strip=True) if time_elem else ""
                start_time = self.parse_match_time(time_text)
                
                # –¢—É—Ä–Ω–∏—Ä
                tournament_elem = match_elem.find("div", class_="tournament")
                tournament = tournament_elem.get_text(strip=True) if tournament_elem else "KHL"
                
                # –§–∏—á–∏ –¥–ª—è ML
                features = {
                    "tournament": tournament,
                    "period": self.extract_period(match_elem),
                    "format": "Regular",
                    "stage": "Regular Season",
                    "home_advantage": True
                }
                
                match = Match(
                    sport="khl",
                    team1=team1,
                    team2=team2,
                    score=score,
                    status=status,
                    start_time=start_time,
                    features=features
                )
                
                matches.append(match)
                
            except Exception as e:
                logger.error(f"Error parsing result element: {e}")
                continue
        
        return matches
    
    async def get_live_matches(self) -> List[Match]:
        """–ü–æ–ª—É—á–∏—Ç—å live –º–∞—Ç—á–∏"""
        matches = []
        
        async with aiohttp.ClientSession() as session:
            # –ü—Ä–æ–±—É–µ–º –∫–∞–ª–µ–Ω–¥–∞—Ä—å
            html = await self.fetch_page(session, self.calendar_url)
            if html:
                page_matches = await self.parse_calendar_page(html)
                # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ live –º–∞—Ç—á–∏ (—Å–µ–π—á–∞—Å –∏–≥—Ä–∞—é—â–∏–µ—Å—è)
                current_time = datetime.now()
                matches = [
                    m for m in page_matches 
                    if m.start_time and 
                    abs((m.start_time - current_time).total_seconds()) < 7200 and  # –í –ø—Ä–µ–¥–µ–ª–∞—Ö 2 —á–∞—Å–æ–≤
                    m.status == "upcoming"
                ]
        
        logger.info(f"üèí Found {len(matches)} live KHL matches")
        return matches
    
    async def get_upcoming_matches(self, hours: int = 24) -> List[Match]:
        """–ü–æ–ª—É—á–∏—Ç—å –ø—Ä–µ–¥—Å—Ç–æ—è—â–∏–µ –º–∞—Ç—á–∏"""
        matches = []
        
        async with aiohttp.ClientSession() as session:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–∞–ª–µ–Ω–¥–∞—Ä—å
            html = await self.fetch_page(session, self.calendar_url)
            if html:
                page_matches = await self.parse_calendar_page(html)
                # –§–∏–ª—å—Ç—Ä—É–µ–º –ø—Ä–µ–¥—Å—Ç–æ—è—â–∏–µ –º–∞—Ç—á–∏ –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–º –¥–∏–∞–ø–∞–∑–æ–Ω–µ
                cutoff_time = datetime.now() + timedelta(hours=hours)
                matches = [
                    m for m in page_matches 
                    if m.status == "upcoming" and m.start_time and m.start_time <= cutoff_time
                ]
        
        logger.info(f"‚è∞ Found {len(matches)} upcoming KHL matches in next {hours} hours")
        return matches
    
    async def get_all_matches(self) -> List[Match]:
        """–ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ –º–∞—Ç—á–∏"""
        all_matches = []
        
        async with aiohttp.ClientSession() as session:
            # –ü—Ä–æ–±—É–µ–º –∫–∞–ª–µ–Ω–¥–∞—Ä—å
            html = await self.fetch_page(session, self.calendar_url)
            if html:
                all_matches = await self.parse_calendar_page(html)
            
            # –ï—Å–ª–∏ –º–∞—Ç—á–µ–π –º–∞–ª–æ, –ø—Ä–æ–±—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            if len(all_matches) < 5:
                html_results = await self.fetch_page(session, self.results_url)
                if html_results:
                    result_matches = await self.parse_results_page(html_results)
                    all_matches.extend(result_matches)
        
        logger.info(f"üìä Found {len(all_matches)} total KHL matches")
        return all_matches
    
    async def update_database(self):
        """–û–±–Ω–æ–≤–∏—Ç—å –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö –∞–∫—Ç—É–∞–ª—å–Ω—ã–º–∏ –º–∞—Ç—á–∞–º–∏"""
        try:
            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –º–∞—Ç—á–∏
            matches = await self.get_all_matches()
            
            if not matches:
                logger.warning("No matches found, using fallback")
                return await self.get_fallback_matches()
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
            saved_count = 0
            for match in matches:
                try:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∂–µ —Ç–∞–∫–æ–π –º–∞—Ç—á
                    existing_matches = await db_manager.get_matches(
                        sport="khl", 
                        limit=1000
                    )
                    
                    # –ò—â–µ–º –¥—É–±–ª–∏–∫–∞—Ç –ø–æ –∫–æ–º–∞–Ω–¥–∞–º –∏ –≤—Ä–µ–º–µ–Ω–∏
                    is_duplicate = False
                    for existing in existing_matches:
                        if (existing.team1 == match.team1 and 
                            existing.team2 == match.team2 and 
                            existing.start_time and 
                            match.start_time and
                            abs((existing.start_time - match.start_time).total_seconds()) < 3600):
                            is_duplicate = True
                            break
                    
                    if not is_duplicate:
                        await db_manager.add_match(match)
                        saved_count += 1
                        
                except Exception as e:
                    logger.error(f"Error saving match {match.team1} vs {match.team2}: {e}")
                    continue
            
            logger.info(f"üíæ Saved {saved_count} new KHL matches to database")
            return matches
            
        except Exception as e:
            logger.error(f"Error updating KHL database: {e}")
            return await self.get_fallback_matches()
    
    async def get_fallback_matches(self) -> List[Match]:
        """Fallback –º–∞—Ç—á–∏, –µ—Å–ª–∏ –ø–∞—Ä—Å–∏–Ω–≥ –Ω–µ —É–¥–∞–ª—Å—è"""
        logger.warning("Using fallback KHL matches")
        
        fallback_matches = [
            Match(
                sport="khl",
                team1="CSKA Moscow",
                team2="SKA St. Petersburg",
                status="live",
                score="2:1",
                start_time=datetime.now() - timedelta(minutes=25),
                features={
                    "tournament": "KHL Regular Season",
                    "period": "2nd",
                    "format": "Regular",
                    "stage": "Regular Season",
                    "home_advantage": True
                }
            ),
            Match(
                sport="khl",
                team1="Ak Bars Kazan",
                team2="Metallurg Magnitogorsk",
                status="upcoming",
                start_time=datetime.now() + timedelta(hours=3),
                features={
                    "tournament": "KHL Regular Season",
                    "period": "Regular",
                    "format": "Regular",
                    "stage": "Regular Season",
                    "home_advantage": True
                }
            ),
            Match(
                sport="khl",
                team1="Lokomotiv Yaroslavl",
                team2="Dinamo Moscow",
                status="upcoming",
                start_time=datetime.now() + timedelta(hours=6),
                features={
                    "tournament": "KHL Regular Season",
                    "period": "Regular",
                    "format": "Regular",
                    "stage": "Regular Season",
                    "home_advantage": True
                }
            )
        ]
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º fallback –º–∞—Ç—á–∏
        for match in fallback_matches:
            try:
                await db_manager.add_match(match)
            except Exception as e:
                logger.error(f"Error saving fallback match: {e}")
        
        return fallback_matches

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –ø–∞—Ä—Å–µ—Ä–∞
khl_parser = KHLParser()
            "https://www.flashscore.ru/hockey/russia/khl/",
            "https://ru.sofascore.com/tournament/211/khl"
        ]
        self.odds_sources = [
            "https://www.flashscore.ru/odds-comparison/hockey/russia/khl/",
            "https://ru.sofascore.com/tournament/211/khl/odds"
        ]
    
    async def parse_matches(self) -> List[ParsedMatch]:
        """–ü–∞—Ä—Å–∏–Ω–≥ –ø—Ä–µ–¥—Å—Ç–æ—è—â–∏—Ö –º–∞—Ç—á–µ–π –ö–•–õ"""
        matches = []
        
        # –ü–∞—Ä—Å–∏–º —Å Flashscore
        flashscore_matches = await self._parse_flashscore_matches()
        matches.extend(flashscore_matches)
        
        # –ü–∞—Ä—Å–∏–º —Å SofaScore
        sofascore_matches = await self._parse_sofascore_matches()
        matches.extend(sofascore_matches)
        
        # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
        unique_matches = self._remove_duplicates(matches)
        
        logger.info(f"Parsed {len(unique_matches)} KHL matches")
        return unique_matches
    
    async def parse_live_matches(self) -> List[ParsedMatch]:
        """–ü–∞—Ä—Å–∏–Ω–≥ live –º–∞—Ç—á–µ–π –ö–•–õ"""
        matches = []
        
        # Live –º–∞—Ç—á–∏ —Å Flashscore
        live_matches = await self._parse_flashscore_live_matches()
        matches.extend(live_matches)
        
        logger.info(f"Parsed {len(matches)} KHL live matches")
        return matches
    
    async def parse_odds(self, match_id: str) -> Dict[str, float]:
        """–ü–∞—Ä—Å–∏–Ω–≥ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–æ–≤ –¥–ª—è –º–∞—Ç—á–∞"""
        odds = {}
        
        try:
            # –ü–æ–ª—É—á–∞–µ–º –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã —Å —Ä–∞–∑–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
            flashscore_odds = await self._parse_flashscore_odds(match_id)
            odds.update(flashscore_odds)
            
            # –ï—Å–ª–∏ –Ω–µ—Ç –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–æ–≤, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è
            if not odds:
                odds = {'odds1': 2.10, 'odds2': 3.20, 'odds_draw': 4.50}
            
        except Exception as e:
            logger.error(f"Error parsing KHL odds for {match_id}: {e}")
            odds = {'odds1': 2.10, 'odds2': 3.20, 'odds_draw': 4.50}
        
        return odds
    
    async def _parse_flashscore_matches(self) -> List[ParsedMatch]:
        """–ü–∞—Ä—Å–∏–Ω–≥ –º–∞—Ç—á–µ–π —Å Flashscore"""
        matches = []
        
        try:
            url = "https://www.flashscore.ru/hockey/russia/khl/"
            content = await self.get_page_content(url)
            
            if not content:
                return matches
            
            soup = BeautifulSoup(content, 'html.parser')
            
            # –ò—â–µ–º –±–ª–æ–∫–∏ —Å –º–∞—Ç—á–∞–º–∏
            match_elements = soup.find_all('div', class_='event__match')
            
            for element in match_elements:
                try:
                    match_data = self._extract_flashscore_match_data(element)
                    if match_data:
                        matches.append(match_data)
                except Exception as e:
                    logger.error(f"Error extracting Flashscore match: {e}")
                    continue
        
        except Exception as e:
            logger.error(f"Error parsing Flashscore matches: {e}")
        
        return matches
    
    async def _parse_flashscore_live_matches(self) -> List[ParsedMatch]:
        """–ü–∞—Ä—Å–∏–Ω–≥ live –º–∞—Ç—á–µ–π —Å Flashscore"""
        matches = []
        
        try:
            url = "https://www.flashscore.ru/hockey/russia/khl/"
            content = await self.get_page_content(url)
            
            if not content:
                return matches
            
            soup = BeautifulSoup(content, 'html.parser')
            
            # –ò—â–µ–º live –º–∞—Ç—á–∏ (–æ–±—ã—á–Ω–æ –∏–º–µ—é—Ç —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π –∫–ª–∞—Å—Å)
            live_elements = soup.find_all('div', class_='event__match--live')
            
            for element in live_elements:
                try:
                    match_data = self._extract_flashscore_live_match_data(element)
                    if match_data:
                        matches.append(match_data)
                except Exception as e:
                    logger.error(f"Error extracting Flashscore live match: {e}")
                    continue
        
        except Exception as e:
            logger.error(f"Error parsing Flashscore live matches: {e}")
        
        return matches
    
    async def _parse_sofascore_matches(self) -> List[ParsedMatch]:
        """–ü–∞—Ä—Å–∏–Ω–≥ –º–∞—Ç—á–µ–π —Å SofaScore"""
        matches = []
        
        try:
            url = "https://ru.sofascore.com/tournament/211/khl"
            content = await self.get_page_content(url)
            
            if not content:
                return matches
            
            soup = BeautifulSoup(content, 'html.parser')
            
            # –ò—â–µ–º –º–∞—Ç—á–∏
            match_elements = soup.find_all('div', class_='sc-match-row')
            
            for element in match_elements:
                try:
                    match_data = self._extract_sofascore_match_data(element)
                    if match_data:
                        matches.append(match_data)
                except Exception as e:
                    logger.error(f"Error extracting SofaScore match: {e}")
                    continue
        
        except Exception as e:
            logger.error(f"Error parsing SofaScore matches: {e}")
        
        return matches
    
    def _extract_flashscore_match_data(self, element) -> Optional[ParsedMatch]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –º–∞—Ç—á–∞ —Å Flashscore"""
        try:
            # –ö–æ–º–∞–Ω–¥—ã
            home_team = element.find('div', class_='event__participant--home')
            away_team = element.find('div', class_='event__participant--away')
            
            if not home_team or not away_team:
                return None
            
            team1 = home_team.get_text(strip=True)
            team2 = away_team.get_text(strip=True)
            
            # –í—Ä–µ–º—è –º–∞—Ç—á–∞
            time_element = element.find('div', class_='event__time')
            if not time_element:
                return None
            
            time_text = time_element.get_text(strip=True)
            match_time = self._parse_match_time(time_text)
            
            # –¢—É—Ä–Ω–∏—Ä (–¥–ª—è –ö–•–õ —ç—Ç–æ –±—É–¥–µ—Ç "–ö–•–õ")
            tournament = "–ö–•–õ"
            
            # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã
            odds = self._extract_flashscore_match_odds(element)
            
            # ID –º–∞—Ç—á–∞
            match_id = self.generate_match_id(team1, team2, match_time)
            
            return ParsedMatch(
                id=match_id,
                team1=team1,
                team2=team2,
                tournament=tournament,
                match_time=match_time,
                odds1=odds.get('odds1', 2.10),
                odds2=odds.get('odds2', 3.20),
                odds_draw=odds.get('odds_draw', 4.50)
            )
        
        except Exception as e:
            logger.error(f"Error extracting Flashscore match data: {e}")
            return None
    
    def _extract_flashscore_live_match_data(self, element) -> Optional[ParsedMatch]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö live –º–∞—Ç—á–∞ —Å Flashscore"""
        try:
            # –ö–æ–º–∞–Ω–¥—ã
            home_team = element.find('div', class_='event__participant--home')
            away_team = element.find('div', class_='event__participant--away')
            
            if not home_team or not away_team:
                return None
            
            team1 = home_team.get_text(strip=True)
            team2 = away_team.get_text(strip=True)
            
            # –°—á–µ—Ç
            home_score = element.find('div', class_='event__score--home')
            away_score = element.find('div', class_='event__score--away')
            
            score1 = int(home_score.get_text(strip=True)) if home_score else 0
            score2 = int(away_score.get_text(strip=True)) if away_score else 0
            
            # –í—Ä–µ–º—è –≤ –º–∞—Ç—á–µ
            period_element = element.find('div', class_='event__stage')
            period_text = period_element.get_text(strip=True) if period_element else "1-–π –ø–µ—Ä–∏–æ–¥"
            
            # ID –º–∞—Ç—á–∞
            match_id = self.generate_match_id(team1, team2, datetime.now())
            
            return ParsedMatch(
                id=match_id,
                team1=team1,
                team2=team2,
                tournament="–ö–•–õ",
                match_time=datetime.now(),
                odds1=1.0,  # Live –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã –±—É–¥—É—Ç –æ–±–Ω–æ–≤–ª–µ–Ω—ã –æ—Ç–¥–µ–ª—å–Ω–æ
                odds2=1.0,
                odds_draw=1.0,
                status='live',
                score1=score1,
                score2=score2,
                live_data={
                    'source': 'flashscore',
                    'live': True,
                    'period': period_text
                }
            )
        
        except Exception as e:
            logger.error(f"Error extracting Flashscore live match data: {e}")
            return None
    
    def _extract_sofascore_match_data(self, element) -> Optional[ParsedMatch]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –º–∞—Ç—á–∞ —Å SofaScore"""
        try:
            # –ö–æ–º–∞–Ω–¥—ã
            teams = element.find_all('div', class_='team-name')
            if len(teams) < 2:
                return None
            
            team1 = teams[0].get_text(strip=True)
            team2 = teams[1].get_text(strip=True)
            
            # –í—Ä–µ–º—è
            time_element = element.find('div', class_='match-time')
            if not time_element:
                return None
            
            time_text = time_element.get_text(strip=True)
            match_time = self._parse_match_time(time_text)
            
            # ID –º–∞—Ç—á–∞
            match_id = self.generate_match_id(team1, team2, match_time)
            
            return ParsedMatch(
                id=match_id,
                team1=team1,
                team2=team2,
                tournament="–ö–•–õ",
                match_time=match_time,
                odds1=2.10,  # –ë—É–¥—É—Ç –æ–±–Ω–æ–≤–ª–µ–Ω—ã
                odds2=3.20,
                odds_draw=4.50
            )
        
        except Exception as e:
            logger.error(f"Error extracting SofaScore match data: {e}")
            return None
    
    def _extract_flashscore_match_odds(self, element) -> Dict[str, float]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–æ–≤ —Å Flashscore"""
        odds = {}
        
        try:
            # –ò—â–µ–º –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã –≤ —ç–ª–µ–º–µ–Ω—Ç–µ
            odds_elements = element.find_all('div', class_='event__odd')
            
            if len(odds_elements) >= 2:
                odds1_text = odds_elements[0].get_text(strip=True)
                odds2_text = odds_elements[1].get_text(strip=True)
                
                odds['odds1'] = self._parse_odds_value(odds1_text)
                odds['odds2'] = self._parse_odds_value(odds2_text)
                
                if len(odds_elements) >= 3:
                    odds_draw_text = odds_elements[2].get_text(strip=True)
                    odds['odds_draw'] = self._parse_odds_value(odds_draw_text)
        
        except Exception as e:
            logger.error(f"Error extracting Flashscore odds: {e}")
        
        return odds
    
    def _parse_match_time(self, time_text: str) -> datetime:
        """–ü–∞—Ä—Å–∏–Ω–≥ –≤—Ä–µ–º–µ–Ω–∏ –º–∞—Ç—á–∞"""
        try:
            # –†–∞–∑–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è –ö–•–õ
            if '—Å–µ–≥–æ–¥–Ω—è' in time_text.lower():
                time_part = re.search(r'(\d{1,2}:\d{2})', time_text)
                if time_part:
                    hour, minute = map(int, time_part.group(1).split(':'))
                    today = datetime.now().replace(hour=hour, minute=minute, second=0, microsecond=0)
                    return today
            
            elif '–∑–∞–≤—Ç—Ä–∞' in time_text.lower():
                time_part = re.search(r'(\d{1,2}:\d{2})', time_text)
                if time_part:
                    hour, minute = map(int, time_part.group(1).split(':'))
                    tomorrow = datetime.now() + timedelta(days=1)
                    return tomorrow.replace(hour=hour, minute=minute, second=0, microsecond=0)
            
            else:
                # –ü–æ–ª–Ω–∞—è –¥–∞—Ç–∞ –∏–ª–∏ —Ç–æ–ª—å–∫–æ –≤—Ä–µ–º—è
                date_patterns = [
                    r'(\d{4}-\d{2}-\d{2} \d{2}:\d{2})',
                    r'(\d{2}\.\d{2}\.\d{4} \d{2}:\d{2})',
                    r'(\d{1,2}:\d{2})',
                ]
                
                for pattern in date_patterns:
                    match = re.search(pattern, time_text)
                    if match:
                        time_str = match.group(1)
                        if len(time_str) == 5:  # –¢–æ–ª—å–∫–æ –≤—Ä–µ–º—è
                            hour, minute = map(int, time_str.split(':'))
                            today = datetime.now().replace(hour=hour, minute=minute, second=0, microsecond=0)
                            return today
                        elif '.' in time_str:  # –§–æ—Ä–º–∞—Ç –î–î.–ú–ú.–ì–ì–ì–ì –ß–ß:–ú–ú
                            return datetime.strptime(time_str, '%d.%m.%Y %H:%M')
                        else:  # –§–æ—Ä–º–∞—Ç –ì–ì–ì–ì-–ú–ú-–î–î –ß–ß:–ú–ú
                            return datetime.strptime(time_str, '%Y-%m-%d %H:%M')
            
            # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –≤—Ä–µ–º—è —á–µ—Ä–µ–∑ 24 —á–∞—Å–∞
            return datetime.now() + timedelta(hours=24)
        
        except Exception as e:
            logger.error(f"Error parsing KHL match time '{time_text}': {e}")
            return datetime.now() + timedelta(hours=24)
    
    def _parse_odds_value(self, odds_text: str) -> float:
        """–ü–∞—Ä—Å–∏–Ω–≥ –∑–Ω–∞—á–µ–Ω–∏—è –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞"""
        try:
            # –£–¥–∞–ª—è–µ–º –≤—Å–µ —Å–∏–º–≤–æ–ª—ã –∫—Ä–æ–º–µ —Ü–∏—Ñ—Ä –∏ —Ç–æ—á–∫–∏
            clean_text = re.sub(r'[^\d.]', '', odds_text)
            if clean_text:
                return float(clean_text)
            return 2.10  # –ó–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è –ö–•–õ
        except:
            return 2.10
    
    def _remove_duplicates(self, matches: List[ParsedMatch]) -> List[ParsedMatch]:
        """–£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –º–∞—Ç—á–µ–π"""
        seen = set()
        unique_matches = []
        
        for match in matches:
            # –°–æ–∑–¥–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∫–ª—é—á –∏–∑ –∫–æ–º–∞–Ω–¥ –∏ –≤—Ä–µ–º–µ–Ω–∏
            key = f"{match.team1}_{match.team2}_{match.match_time.strftime('%Y%m%d_%H%M')}"
            
            if key not in seen:
                seen.add(key)
                unique_matches.append(match)
        
        return unique_matches
